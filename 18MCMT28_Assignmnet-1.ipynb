{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "K. Sai Somanath, 18MCMT28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random samples from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genNormalSamples(number_of_samples, mean, cov):\n",
    "    return np.random.multivariate_normal(mean, cov, number_of_samples).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Euclidean distance between two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    sub = x - y\n",
    "    return numpy.sqrt(numpy.einsum('ij,ij->i', sub, sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(a):\n",
    "    if not a.shape:\n",
    "        return a\n",
    "    else:\n",
    "        return np.linalg.inv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(temp, cov_inv):\n",
    "    if not temp.shape:\n",
    "        # print('here')\n",
    "        return np.sqrt(temp ** 2 * cov_inv)\n",
    "    else:\n",
    "        # print('Shape:', np.dot(np.dot(temp.T,cov_inv),temp).shape)\n",
    "        return np.sqrt(np.dot(np.dot(temp.T,cov_inv),temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_dist(x, mu, cov):\n",
    "    cov_inv = inverse(cov)\n",
    "    temp = x - mu\n",
    "    # print(norm(temp, cov_inv))\n",
    "    return norm(temp, cov_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Discriminent function\n",
    "\n",
    "$\n",
    "g_i(x) = -\\frac{1}{2}(x_i - \\mu_i)^t\\Sigma^{-1}(x_i - \\mu_i) - \\frac{d}{2}\\ln{2\\pi} - \\frac{1}{2}\\ln{\\lvert \\Sigma_i\\rvert} + \\ln{P(\\omega_i)}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det(mat):\n",
    "    if not mat.shape:\n",
    "        return mat\n",
    "    else:\n",
    "        return np.linalg.det(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_function(x, mu, cov, d, p_w):\n",
    "    mahala_dist = mahalanobis_dist(x, mu, cov)\n",
    "    return -((0.5) * mahala_dist) - ((d / 2) * np.log(np.pi * 2)) - (0.5 * np.log(det(cov))) + np.log(p_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data_dhs_chap2.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichotomizer - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class data\n",
    "x_samples = data[:5, :1]\n",
    "y_samples = data[10:15, :1]\n",
    "samples = np.concatenate((x_samples, y_samples))\n",
    "\n",
    "# Generate traget values\n",
    "targets = [0] * 5 + [1] * 5\n",
    "predicted = []\n",
    "\n",
    "# Mean and covariace\n",
    "mu1 = np.mean(x_samples, axis=0)\n",
    "cov1 = np.cov(x_samples.T)\n",
    "mu2 = np.mean(y_samples, axis=0)\n",
    "cov2 = np.cov(y_samples.T)\n",
    "\n",
    "for sample in samples:    \n",
    "    g1 = disc_function(sample, mu1, cov1, 1, 0.5)\n",
    "    g2 = disc_function(sample, mu2, cov2, 1, 0.5)\n",
    "    if g1 - g2 > 0:\n",
    "        predicted.append(0)\n",
    "    elif g1 - g2 < 0:\n",
    "        predicted.append(1)\n",
    "    else:\n",
    "        predicted.append(-1)\n",
    "    \n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate\n",
    "\n",
    "The error rate turns out to be 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.array(predicted) != np.array(targets)).mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichotomizer - Two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class data\n",
    "x_samples = data[:5, :2]\n",
    "y_samples = data[10:15, :2]\n",
    "samples = np.concatenate((x_samples, y_samples))\n",
    "\n",
    "# Generate traget values\n",
    "targets = [0] * 5 + [1] * 5\n",
    "predicted = []\n",
    "\n",
    "# Mean and covariace\n",
    "mu1 = np.mean(x_samples, axis=0)\n",
    "cov1 = np.cov(x_samples.T)\n",
    "mu2 = np.mean(y_samples, axis=0)\n",
    "cov2 = np.cov(y_samples.T)\n",
    "\n",
    "for sample in samples:\n",
    "    g1 = disc_function(sample.reshape(2,1), mu1.reshape(2,1), cov1, 2, 0.5)\n",
    "    g2 = disc_function(sample.reshape(2,1), mu2.reshape(2,1), cov2, 2, 0.5)\n",
    "    if g1 - g2 > 0:\n",
    "        predicted.append(0)\n",
    "    elif g1 - g2 < 0:\n",
    "        predicted.append(1)\n",
    "    else:\n",
    "        predicted.append(-1)\n",
    "        \n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate\n",
    "The error rate turns out to be 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(predicted) != np.array(targets)).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichotomizer - Three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class data\n",
    "x_samples = data[:5, :3]\n",
    "y_samples = data[10:15, :3]\n",
    "samples = np.concatenate((x_samples, y_samples))\n",
    "\n",
    "# Generate traget values\n",
    "targets = [0] * 5 + [1] * 5\n",
    "predicted = []\n",
    "\n",
    "# Mean and covariace\n",
    "mu1 = np.mean(x_samples, axis=0)\n",
    "cov1 = np.cov(x_samples.T)\n",
    "mu2 = np.mean(y_samples, axis=0)\n",
    "cov2 = np.cov(y_samples.T)\n",
    "\n",
    "for sample in samples:\n",
    "    g1 = disc_function(sample.reshape(3,1), mu1.reshape(3,1), cov1, 3, 0.5)\n",
    "    g2 = disc_function(sample.reshape(3,1), mu2.reshape(3,1), cov2, 3, 0.5)\n",
    "    if g1 - g2 > 0:\n",
    "        predicted.append(0)\n",
    "    elif g1 - g2 < 0:\n",
    "        predicted.append(1)\n",
    "    else:\n",
    "        predicted.append(-1)\n",
    "        \n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate\n",
    "The error rate turns out to be 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(predicted) != np.array(targets)).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying new points into categories with uniform probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class data\n",
    "x_samples = data[:10, :3]\n",
    "y_samples = data[10:20, :3]\n",
    "z_samples = data[20:, :3]\n",
    "\n",
    "# Mean and covariace\n",
    "mu1 = np.mean(x_samples, axis=0)\n",
    "cov1 = np.cov(x_samples.T)\n",
    "mu2 = np.mean(y_samples, axis=0)\n",
    "cov2 = np.cov(y_samples.T)\n",
    "mu3 = np.mean(z_samples, axis=0)\n",
    "cov3 = np.cov(z_samples.T)\n",
    "\n",
    "## The DFs\n",
    "g1 = disc_function(sample.reshape(3,1), mu1.reshape(3,1), cov1, 2, 0.33)\n",
    "g2 = disc_function(sample.reshape(3,1), mu2.reshape(3,1), cov2, 2, 0.33)\n",
    "g3 = disc_function(sample.reshape(3,1), mu3.reshape(3,1), cov3, 2, 0.33)\n",
    "\n",
    "data = [[1, 2, 1], [5, 3, 2], [0, 0, 0], [1, 0, 0]]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "for point in data:\n",
    "    for mu, cov in zip([mu1, mu2, mu3], [cov1, cov2, cov3]):\n",
    "        distances.append(np.asscalar(mahalanobis_dist(point.reshape(3,1), mu.reshape(3,1), cov)))\n",
    "distances = np.array(distances).reshape(4, 3)\n",
    "np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "We can see that points are classified as follows:\n",
    "\n",
    "(1, 2, 1) --> 1\n",
    "\n",
    "(5, 3, 2) --> 2\n",
    "\n",
    "(0, 0, 0) --> 1\n",
    "\n",
    "(1, 0, 0) --> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "for point in data:\n",
    "    for mu, cov in zip([mu1, mu2, mu3], [cov1, cov2, cov3]):\n",
    "        distances.append(np.asscalar(mahalanobis_dist(point.reshape(3,1), mu.reshape(3,1), cov)))\n",
    "distances = np.array(distances).reshape(4, 3)\n",
    "np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The classification remains the same as the *Mahalanobis* distances is independent of the **Prior probabilites**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laod data\n",
    "iris = np.genfromtxt('iris.csv', delimiter=',', skip_header=1, usecols=(0,1,2,3))\n",
    "iris = iris.reshape(3, 50, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.006, 3.418, 1.464, 0.244],\n",
       "       [5.936, 2.77 , 4.26 , 1.326],\n",
       "       [6.588, 2.974, 5.552, 2.026]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.mean(iris, axis=1)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.cov(iris.T).shape\n",
    "covs = [np.cov(x.T) for x in iris]\n",
    "covs = np.array(covs)\n",
    "covs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDF for Case 1 is given by the equation: \n",
    "\n",
    "$g_i(x) = W_i^Tx+W_{i0}$\n",
    "\n",
    "where $W_i= \\frac{\\mu_i}{\\sigma^2} \\implies W_i^T= \\frac{\\mu_i^T}{\\sigma^2}$\n",
    "\n",
    "and $W_{i0}= \\frac{-\\mu_i^T\\mu_i}{2\\sigma^2}+ ln(P(\\omega_i))$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.mean([covs[i].diagonal() for i in range(covs.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $W^T$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.93023131 22.48412517  9.63041523  1.6050692 ]\n",
      "[39.04791311 18.22148237 28.02292956  8.72263019]\n",
      "[43.33686853 19.56342547 36.52190256 13.32733692]\n"
     ]
    }
   ],
   "source": [
    "for mu in means:\n",
    "    print(mu / var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $W_0$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-129.19363356697767\n",
      "-207.70151526763146\n",
      "-287.82646472325564\n"
     ]
    }
   ],
   "source": [
    "for mu in means:\n",
    "    val = ((- 0.5 * (np.dot(mu, mu.T))) / var) + np.log(1/3)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above calculations it is evident that we will have the following equations:\n",
    "\n",
    "$g_1(x) = 32.93* x_1 + 22.48 * x_2 + 9.63 * x_3 + 1.60 *x_4 - 129.19$\n",
    "\n",
    "$g_2(x) = 39.05* x_1 + 18.22 * x_2 + 28.02 * x_3 + 8.72 *x_4 - 207.70$\n",
    "\n",
    "$g_3(x) = 43.34* x_1 + 19.56 * x_2 + 36.52 * x_3 + 13.33 *x_4 - 287.83$\n",
    "\n",
    "We will be able to construct the equations in a **similar manner for all other cases**.\n",
    "\n",
    "Below, we list the values of the $W$ and the $W_{i0}$ matrices, using which the equations are constructed for **case 2**.\n",
    "\n",
    "\n",
    "\n",
    "## Case 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g_i(x) = W_i^Tx+W_{i0}$ \n",
    "\n",
    "where $W_i= \\Sigma^{-1}\\mu_i \\implies  W_i^T= \\mu_i^T(\\Sigma^{-1})^T$\n",
    "\n",
    "and $W_{i0}= \\frac{-1}{2}\\mu_i^T\\Sigma^{-1}\\mu_i+ ln(P(\\omega_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mean = np.mean(covs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $W^T$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23.46638411  23.56828007 -16.20296668 -18.02533894]]\n",
      "[[15.70349917  6.95425598  5.28429325  6.29830031]]\n",
      "[[12.49061995  3.44398145 12.82207622 21.06272174]]\n"
     ]
    }
   ],
   "source": [
    "for mu in zip(means):\n",
    "    print(np.dot(mu, np.linalg.inv(cov_mean).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $W_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-86.05349938690331\n",
      "-72.76956006760176\n",
      "-104.29453550375828\n"
     ]
    }
   ],
   "source": [
    "for mu in means:\n",
    "    dist = -0.5 * np.dot(np.dot(mu, np.linalg.inv(cov_mean)), mu.T)\n",
    "    print(dist + np.log(1 / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3:\n",
    "\n",
    "$\n",
    "g_i(x) = x^tW_ix + w_i^tx + w_{i0}\n",
    "$\n",
    "Where,\n",
    "\n",
    "$\n",
    "W_i = -\\frac{1}{2}\\Sigma_i\n",
    "$\n",
    "\n",
    "$\n",
    "w_i = \\Sigma_i^{-1}\\mu_i\n",
    "$\n",
    "\n",
    "$\n",
    "w_{i0} = -\\frac{1}{2}\\mu^t_i\\Sigma_i^{-1}\\mu_i  -\\frac{1}{2}\\ln \\lvert \\Sigma_i \\rvert + \\ln(P(\\omega_i))\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $W$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.06212449, -0.05014898, -0.00806939, -0.00527347],\n",
       "        [-0.05014898, -0.0725898 , -0.00584082, -0.00571837],\n",
       "        [-0.00806939, -0.00584082, -0.01505306, -0.00284898],\n",
       "        [-0.00527347, -0.00571837, -0.00284898, -0.00574694]],\n",
       "\n",
       "       [[-0.13321633, -0.04259184, -0.09144898, -0.0278898 ],\n",
       "        [-0.04259184, -0.04923469, -0.04132653, -0.02060204],\n",
       "        [-0.09144898, -0.04132653, -0.11040816, -0.03655102],\n",
       "        [-0.0278898 , -0.02060204, -0.03655102, -0.01955306]],\n",
       "\n",
       "       [[-0.20217143, -0.04688163, -0.1516449 , -0.02454694],\n",
       "        [-0.04688163, -0.05200204, -0.0356898 , -0.02381429],\n",
       "        [-0.1516449 , -0.0356898 , -0.15229388, -0.02441224],\n",
       "        [-0.02454694, -0.02381429, -0.02441224, -0.03771633]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wi = - 0.5 * covs\n",
    "Wi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $w$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 44.6351704 ,  -7.71338075,  33.07861577, -28.45246274]),\n",
       " array([ 18.0128645 ,  15.96070005,   3.26878502, -14.71255747]),\n",
       " array([ 7.37247478, 13.2452613 ,  6.23406948,  9.66197608])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wi = [np.dot(np.linalg.inv(c), mu.T) for c, mu in zip(covs, means)]\n",
    "wi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $w_0$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-113.86317185,  -68.43728769,  -67.7090772 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wi0 = []\n",
    "for c, mu in zip(covs, means):\n",
    "    dist = -0.5 * np.dot(np.dot(mu, np.linalg.inv(c)), mu.T)\n",
    "    wi0.append(dist - (0.5 * np.log(np.linalg.det(c))) + np.log(1 / 3))\n",
    "wi0 = np.array(wi0)\n",
    "wi0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the following values:\n",
    "1. $W_i, W_j, W_k$\n",
    "2. $w_i, w_j, w_k$\n",
    "3. $w_{i0}, w_{j0}, w_{k0}$\n",
    "Using the above values we get the Quadractic discriminent function $g_i(x), g_j(x), g_k(x)$\n",
    "\n",
    "Hence, we now have constructed the Linear discriminent and the Quadractic discriminent functions for Cases 1,2 and Case 3 respectively..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
